// Use from the standard library
use std::{
    borrow::Cow,
    collections::{BTreeMap, BTreeSet, HashSet},
    ffi::OsString,
    fs::{create_dir, File},
    io::{stderr, BufWriter, Write},
    path::{Path, PathBuf},
    str::FromStr,
    sync::Arc,
};

// Use from external dependencies
use ahtml::{
    att, flat::Flat, util::SoftPre, AId, ASlice, HtmlAllocator, HtmlAllocatorPool, Node, Print,
    SerHtmlFrag, ToASlice,
};
use anyhow::{anyhow, bail, Context, Result};
use chrono::Local;
use clap::Parser;
use itertools::{intersperse_with, Itertools};
use lazy_static::lazy_static;
use rayon::prelude::{
    IndexedParallelIterator, IntoParallelIterator, IntoParallelRefIterator, ParallelIterator,
};

use roxmltree::Document;
use walkdir::WalkDir;
// Use from src/*.rs
use xmlhub_indexer::{
    backoff::LoopWithBackoff,
    browser::spawn_browser,
    checkout_context::{CheckedCheckoutContext1, CheckedCheckoutContext2},
    const_util::file_name,
    daemon::{Daemon, DaemonMode},
    file_lock::{file_lock_nonblocking, FileLockError},
    forking_loop::forking_loop,
    git::{git, git_ls_files, git_push, git_status, BaseAndRelPath, GitStatusItem},
    git_check_version::GitLogVersionChecker,
    git_version::{GitVersion, SemVersion},
    modified_xml_document::ModifiedXMLDocument,
    path_util::{AppendToPath, FixupPath},
    rayon_util::ParRun,
    string_tree::StringTree,
    tuple_transpose::TupleTranspose,
    util::{self, format_anchor_name, format_string_list},
    util::{append, english_plural, list_get_by_key, InsertValue},
    xml_document::{read_xml_file, XMLDocumentComment},
    xmlhub_indexer_defaults::{SOURCE_CHECKOUT, XMLHUB_CHECKOUT, XMLHUB_INDEXER_BINARY_FILE},
};

struct OutputFile {
    /// Relative path from the top of the xmlhub repository
    path_from_repo_top: &'static str,
}

// -------------------------------------------------------------------------
// Various settings in addition to those imported from
// `xmlhub_indexer_defaults` (see `xmlhub_indexer_defaults.rs` to edit
// those!).

/// Comment added to XML files when blinding `<data>` XML elements
const DEFAULT_COMMENT_FOR_BLINDED_DATA: &str =
    "Sequences removed due to terms of use or privacy concerns";

/// How many seconds to sleep at minimum between runs in daemon
/// mode. Keep in sync with the `Opts` docs above!
const MIN_SLEEP_SECONDS_DEFAULT: f64 = 10.;

/// Do not sleep more than that many seconds between runs.
const MAX_SLEEP_SECONDS: f64 = 1000.;

/// Max size of a single log file in bytes before it is renamed.
const MAX_LOG_FILE_SIZE_DEFAULT: u64 = 1000000;

/// Max number of log files before they are deleted.
const MAX_LOG_FILES_DEFAULT: usize = 100;

/// The index file in HTML format (the one viewed when using `--open`
/// locally).
const HTML_FILE: OutputFile = OutputFile {
    path_from_repo_top: "README.html",
};

/// The index file in markdown format (the one viewed on GitLab).
const MD_FILE: OutputFile = OutputFile {
    path_from_repo_top: "README.md",
};

/// The file describing the attributes (for contributors).
const ATTRIBUTES_FILE: OutputFile = OutputFile {
    path_from_repo_top: "attributes.md",
};

const OUTPUT_FILES: [&OutputFile; 3] = [&HTML_FILE, &MD_FILE, &ATTRIBUTES_FILE];

/// The file name (without the .md or .html suffix) of the file with
/// information on how to contribute.
const CONTRIBUTE_FILENAME: &str = "CONTRIBUTE";

/// The symbol to use in the index page for links to the original
/// XML file.
const DOCUMENT_SYMBOL_PATH: &str = ".index/document.svg";

/// Return the html code for loading the document symbol image
fn document_symbol(html: &HtmlAllocator) -> Result<AId<Node>> {
    html.img(
        [
            att("src", DOCUMENT_SYMBOL_PATH),
            att("style", "vertical-align: -2px;"),
        ],
        [],
    )
}

// -------------------------------------------------------------------------
// Derived values:

/// The name of the command line program.
const PROGRAM_NAME: &str = file_name(XMLHUB_INDEXER_BINARY_FILE);

/// The name of the program in the abstract (repository name).
const REPO_NAME: &str = file_name(SOURCE_CHECKOUT.supposed_upstream_web_url);

/// The value of this constant is generated by the `build.rs` program
/// during compilation. It is the output of running `git describe ..`
/// in `build.rs`.
const PROGRAM_VERSION: &str = env!("GIT_DESCRIBE");

lazy_static! {
    /// Name of the folder where the lock and log files are saved,
    /// placed at the root of the working directory.
    static ref DAEMON_FOLDER_NAME: String = format!(".{PROGRAM_NAME}");
}

// `HtmlAllocator` is an allocator for HTML elements (it manages
// memory efficiently, and provides a method for each HTML element by
// its name, e.g. `html.p(...)` creates a `<p>...</p>`
// element). `HtmlAllocatorPool` is a pool of `HtmlAllocator` that
// re-uses those for performance. The number passed to `new` is the
// limit on the number of allocations an allocator allows (a safety
// feature to limit damage when dealing with attackers of web systems;
// irrelevant here, just choosing a number large enough.) Rust allows
// underscores in numbers to allow for better readability of large
// numbers. `lazy_static!` declares a global variable that is
// initialized on the first access.
lazy_static! {
    static ref HTML_ALLOCATOR_POOL: HtmlAllocatorPool = HtmlAllocatorPool::new(
        5_000_000, // allocation limit
        true, // verify HTML correctness
        Arc::new(format!("change the limit in {}:{}", file!(), line!()))
    );
}

fn get_terminal_width() -> usize {
    let default = 120;
    if let Some((terminal_size::Width(width), _height)) = terminal_size::terminal_size() {
        usize::from(width).checked_sub(4).unwrap_or(default)
    } else {
        default
    }
}

#[derive(PartialEq, Eq, Debug)]
enum BeastMajorVersion {
    One,
    Two,
    Future(u16),
}

impl TryFrom<u16> for BeastMajorVersion {
    type Error = anyhow::Error;

    fn try_from(value: u16) -> Result<Self, Self::Error> {
        match value {
            0 => bail!("not a BEAST major version number: {value}"),
            1 => Ok(BeastMajorVersion::One),
            2 => Ok(BeastMajorVersion::Two),
            n => Ok(BeastMajorVersion::Future(n)),
        }
    }
}

#[derive(PartialEq, Eq, Debug)]
struct BeastVersion {
    major: BeastMajorVersion,
    string: String,
}

impl FromStr for BeastVersion {
    type Err = anyhow::Error;

    fn from_str(s: &str) -> Result<Self, Self::Err> {
        let string = s.trim().to_owned();
        let parts: Vec<&str> = string.split('.').collect();
        if parts.len() < 2 {
            bail!("not a BEAST version number, misses a '.': {string:?}")
        } else {
            let major_num = u16::from_str(parts[0]).with_context(|| {
                anyhow!(
                    "not a BEAST version number, the major number part is \
                     not an unsigned integer: {string:?}"
                )
            })?;
            Ok(Self {
                major: BeastMajorVersion::try_from(major_num)
                    .with_context(|| anyhow!("parsing version number string {string:?}"))?,
                string,
            })
        }
    }
}

fn get_beast_version(document: &Document) -> Result<BeastVersion> {
    let root_element = document.root_element();
    if root_element.tag_name().name() != "beast" {
        // XX check the namespace?
        bail!("not a BEAST file, the root element is not a <beast> element");
    }
    if let Some(version) = root_element.attribute("version") {
        BeastVersion::from_str(version)
    } else {
        bail!("<beast> element is missing the `version` attribute")
    }
}

// =============================================================================
// Specification of the command line interface, using the `clap`
// library crate.

#[derive(clap::Parser, Debug)]
#[clap(next_line_help = true)]
#[clap(set_term_width = get_terminal_width())]
/// Build an index of the files in the XML Hub of the
/// cEvo group at the D-BSSE, ETH Zurich.
struct Opts {
    /// Show the program version. It was copied from `git describe
    /// --tags ..` at compile time.
    // Note: can't name this field `version` as that's special-cased
    // in Clap.
    #[clap(long = "version")]
    v: bool,

    /// Open the XML Hub CONTRIBUTING page in the web browser. If this
    /// doesn't work for you, see the notes for the `--open` option.
    #[clap(long)]
    help_contributing: bool,

    /// Show external modifying commands that are run. Note that this
    /// does not disable `--quiet`.
    #[clap(short, long)]
    verbose: bool,

    /// Suppress some unimportant output; useful with `--daemon` to
    /// reduce the amount of log space required. Note that this does
    /// not disable `--verbose`.
    #[clap(short, long)]
    quiet: bool,

    /// When running in `--daemon start` mode, for the log messages,
    /// use time stamps in the local time zone. The default is to use
    /// UTC.
    #[clap(long)]
    localtime: bool,

    /// When running in `--daemon start` mode, the maximum size of a
    /// log file in bytes before the current file is renamed and a new
    /// one is created instead. Default: 1000000.
    #[clap(long)]
    max_log_file_size: Option<u64>,

    /// When running in `--daemon start` mode, the number of numbered
    /// log files before the oldest files are automatically
    /// deleted. Careful: will delete as many files as needed to get
    /// their count down to the given number (if you give 0 it will
    /// delete them all.) Default: 100.
    #[clap(long)]
    max_log_files: Option<usize>,

    /// Do not run external processes like git or browsers,
    /// i.e. ignore all the options asking to do so. Instead just say
    /// on stderr what would be done. Still writes to the output
    /// files, though.
    #[clap(long)]
    dry_run: bool,

    /// Do not check the program version against versions specified in
    /// the automatic commit messages in the xmlhub repo. Only use if
    /// you know what you're doing.
    #[clap(long)]
    no_version_check: bool,

    /// The subcommand to run. Use `--help` after the sub-command to
    /// get a list of the allowed options there.
    #[clap(subcommand)]
    command: Option<Command>,
}

#[derive(clap::Subcommand, Debug)]
enum Command {
    /// Rebuild the XML Hub index.
    Build(BuildOpts),
    /// Clone the XML Hub repository and apply merge config change.
    CloneTo(CloneOpts),
    /// Prepare some XML file(s) by adding a metadata template to
    /// it/them so that the metadata can more easily be entered via a
    /// text editor, and by default, deleting sequence data.  Careful!: this
    /// replaces the files in place, but keeps the original in the
    /// system trash bin. Also see the `add` subcommand, which leaves
    /// the original file untouched but creates a prepared copy in a
    /// separate directory.
    Prepare(PrepareOpts),
    /// Add some XML file(s) to a XML Hub repository clone and carry
    /// out the `prepare` action on them at the same time. This leaves
    /// the original file unchanged.
    Add(AddOpts),
}

#[derive(clap::Parser, Debug)]
struct BuildOpts {
    /// Add a footer with a timestamp ("Last updated") to the index
    /// files. Note: this causes every run to create modified files
    /// that will be commited even when there were no actual changes,
    /// thus probably not what you want!
    #[clap(long)]
    timestamp: bool,

    /// Write the index files (and commit them if requested) even if
    /// some files had errors and thus won't be indexed; the errors
    /// are written in a section at the top of the index files,
    /// though. The same errors are still printed to stderr, and
    /// reported as exit code 1, too, though--see
    /// `--ok-on-written-errors` to change that. Those errors are also
    /// committed (and pushed if `--push` was given), unless
    /// `--no-commit-errors` is also given.
    #[clap(long, short)]
    write_errors: bool,

    /// If you want to see errors in the browser and hence are using
    /// `--write-errors`, but don't want those to be committed (and
    /// pushed if `--push` was given), this option will prevent those
    /// latter steps (meaning errors are written to the files, but not
    /// committed).
    #[clap(long)]
    no_commit_errors: bool,

    /// If used together with `--write-errors`, does use exit code 0
    /// even if there were errors that were written to the index
    /// files. Errors are still also written to stderr, though--see
    /// `--silent-on-written-errors` to change that.
    #[clap(long, short)]
    ok_on_written_errors: bool,

    /// If used together with `--write-errors`, exits with exit code 0
    /// and does not print any errors to stderr if there are errros
    /// that are written to the index files (it can still give some
    /// other errors, though, like being unable to run Git).
    #[clap(long, short)]
    silent_on_written_errors: bool,

    /// Open the generated `README.html` file in a web browser.
    /// Tries the browsers specified in the `BROWSER` environment
    /// variable (split on ':' into program names or paths (on macOS
    /// don't pass paths into `/Applications`, just give the
    /// application name; you could use paths to scripts)), otherwise
    /// `sensile-browser`, `firefox`, `chromium`, `chrome`, and on
    /// macOS `safari`. Fails if none worked. Note: only opens the
    /// file if it was actually written to (i.e. when there were no
    /// errors or `--write-errors` was given).
    #[clap(long)]
    open: bool,

    /// Same as `--open` but only opens a browser if the file has
    /// changed since the last Git commit to it.
    #[clap(long)]
    open_if_changed: bool,

    /// Git pull from the default remote into the local Git checkout
    /// before creating the index files.
    #[clap(long)]
    pull: bool,

    /// Do not add and commit the output files to the Git
    /// repository. It's better to let `xmlhub` do that (the
    /// default) rather than doing it manually, since it adds its
    /// version information to the commit message and later
    /// invocations of it check whether it needs upgrading. So this
    /// option should only be used temporarily during development.
    #[clap(long)]
    no_commit: bool,

    /// Push the local Git changes to the default remote after
    /// committing. Does nothing if the `--no-commit` option was
    /// given, or if there were no changes.
    #[clap(long)]
    push: bool,

    /// Update the xmlhub repository unattended (e.g. via a cronjob or
    /// similar). Implies --write-errors, --silent-on-written-errors
    /// and --push, and disables --no-commit and --timestamp. Instead
    /// of --pull, uses `git remote update` and `git reset --hard` to
    /// set the local branch to the remote, which avoids the risk for
    /// merge conflicts but throws away local changes!  WARNING: this
    /// will lead to local changes being lost!  Do not use this option
    /// for interactive usage!
    #[clap(long)]
    batch: bool,

    /// Run as a daemon, i.e. do not exit, but run batch conversion
    /// repeatedly. The given string must be one of "run",
    /// "start", "stop", "restart", "status". "run" does not put the
    /// process into the background, "start" (and "restart") does.
    /// Implies `--batch`. You may want to use `--quiet` at the same
    /// time. Also see `--daemon-sleep-time`. When using "start" mode,
    /// writes logs to the directory `.xmlhub/logs/`
    /// under the given `BASE_PATH`.
    #[clap(long)]
    daemon: Option<DaemonMode>,

    /// When running in one of the `--daemon` modes, use the given
    /// number of seconds as the minimum time to sleep between
    /// conversion runs; on errors this interval may be increased
    /// (exponential backoff). The default is 10 seconds.
    #[clap(long)]
    daemon_sleep_time: Option<f64>,

    /// Do not check that the correct branch is checked out in the
    /// xmlhub repository. Only use if you're experimenting on another
    /// branch.
    #[clap(long)]
    no_branch_check: bool,

    /// Ignore untracked files (local files not added to the xmlhub
    /// repository). By default, files are read regardless of whether
    /// they are in Git or not.
    #[clap(long)]
    ignore_untracked: bool,

    /// The path to the base directory of the Git checkout of the XML
    /// Hub.
    base_path: Option<PathBuf>,
}

#[derive(clap::Parser, Debug)]
struct CloneOpts {
    /// Do not show the Git commands that are run (by default, they
    /// are shown even if the global `--verbose` option was not given)
    #[clap(long)]
    no_verbose: bool,

    /// The desired path to the future base directory of the Git
    /// checkout of the XML Hub, i.e. the directory and subdirectory
    /// name where the xmlhub repository should be cloned to. The
    /// parent directory of the given path must exist, the
    /// subdirectory must not exist before running the command.
    base_path: Option<PathBuf>,
}

#[derive(clap::Parser, Debug)]
struct PrepareOpts {
    /// The path(s) to the XML file(s) which should be
    /// modified. Careful: they are modified in place (although the
    /// original is kept in the system trash bin)! Use the `add`
    /// subcommand instead if you really want to copy them. The
    /// metainformation template is added and sequence data is
    /// stripped (unless you provide the `--no-blind` option). .
    files_to_prepare: Vec<PathBuf>,

    /// Do *not* strip the sequences (`<data>` element contents); by
    /// default they are stripped, as safety measure to avoid
    /// accidental exposure of private data. If you can publish the
    /// data and it's not overly large, feel free to use this option!
    #[clap(long)]
    no_blind: bool,

    /// The comment to put above `<data>` elements when blinding the
    /// data (i.e. `--no-blind` is not given). By default, a comment
    /// with regards to terms of use and privacy is given.
    #[clap(long)]
    blind_comment: Option<String>,
    // XX FUTURE idea: --set "header: value"
}

#[derive(clap::Parser, Debug)]
struct AddOpts {
    /// The path to an existing directory inside the Git checkout of
    /// the XML Hub, where the file(s) should be copied to. .
    target_directory: Option<PathBuf>,

    /// The path(s) to the XML file(s), outside of the XML Hub
    /// repository, that you want to add to XML Hub. They are copied,
    /// and a metainformation template is added to them while doing
    /// so, and sequence data is stripped (unless you provide the
    /// `--no-blind` option). .
    files_to_add: Vec<PathBuf>,

    /// Create the `TARGET_DIRECTORY` if it doesn't exist yet. .
    #[clap(long)]
    mkdir: bool,

    /// Do *not* strip the sequences (`<data>` element contents); by
    /// default they are stripped, as safety measure to avoid
    /// accidental exposure of private data. If you can publish the
    /// data and it's not overly large, feel free to use this option!
    #[clap(long)]
    no_blind: bool,

    /// The comment to put above `<data>` elements when blinding the
    /// data (i.e. `--no-blind` is not given). By default, a comment
    /// with regards to terms of use and privacy is given.
    #[clap(long)]
    blind_comment: Option<String>,

    /// Force overwriting of existing files at the target location. .
    #[clap(long, short)]
    force: bool,
    // XX FUTURE idea: --set "header: value"
}

// =============================================================================
// Description of the valid metadata attributes and how they are
// parsed and displayed. First, the definition of the data types for
// the metadata (`struct`, `enum`, `impl`), then, using those, the
// actual description in `METADATA_SPECIFICATION`.

/// An attribute name is a string that identifies an attribute. The
/// string is in the canonical casing as it should be shown in
/// metadata listings in the HTML/Markdown output. To try to avoid
/// making mistakes, we define a wrapper struct `AttributeName` to
/// make it clear everywhere whether we're having a string in
/// canonical casing or not.
#[derive(Debug, PartialEq, Eq, PartialOrd, Ord, Clone, Copy)]
struct AttributeName(&'static str);

/// Get the actual attribute name string
impl AsRef<str> for AttributeName {
    fn as_ref(&self) -> &'static str {
        self.0
    }
}

impl AttributeName {
    /// Generate an anchor name for this attribute with the given
    /// attribute item string.
    fn anchor_name(self, key_string: &str) -> String {
        format!(
            "{}-{}",
            format_anchor_name(self.as_ref()),
            format_anchor_name(key_string)
        )
    }
}

/// Specifies whether an attribute is required
#[derive(Debug, PartialEq, Clone, Copy)]
enum AttributeNeed {
    Optional,
    /// Not "NA", nor the empty string / space only, and for lists not
    /// the empty list (even a list of empty elements like ", , ," is
    /// not OK)
    Required,
}

/// Specifies how an attribute value should be treated
#[derive(Debug, PartialEq, Clone, Copy)]
enum AttributeKind {
    /// A single piece of text, e.g. description or comment. It is
    /// formatted to HTML via `SoftPre`, meaning line breaks and tab
    /// characters are preserved.
    String {
        /// Whether to convert groups of any kind of whitespace
        /// (spaces, tabs, newlines) to a single space. I.e. this
        /// strips space based "markup" if true. Note that in indexes,
        /// values are normalized anyway, so this matters only for the
        /// display in the file info boxes. (StringList items (the
        /// case below) are always normalized btw.)
        normalize_whitespace: bool,
    },
    /// A list of small pieces of text, e.g. keywords. The individual
    /// list elements are cleaned up then formatted to HTML, all
    /// whitespace including line breaks is uniformly replaced with a
    /// single normal space.
    StringList {
        /// This is the separator as used between list items, in the
        /// XML files within the `<!-- -->` parts; e.g. if the items are
        /// separated by spaces, give " ", if separated by commas, give
        /// ",". This does not determine what's used for the HTML
        /// formatting; for that, see the `to_html` method on
        /// AttributeValue.
        input_separator: &'static str,
    },
}

fn text_not(is: bool) -> &'static str {
    if is {
        ""
    } else {
        "not "
    }
}

impl AttributeKind {
    fn is_list(&self) -> bool {
        match self {
            AttributeKind::String {
                normalize_whitespace: _,
            } => false,
            AttributeKind::StringList { input_separator: _ } => true,
        }
    }
    fn to_html(&self, html: &HtmlAllocator) -> Result<AId<Node>> {
        let softpre = SoftPre::default();
        match self {
            AttributeKind::String {
                normalize_whitespace,
            } => softpre.format(
                &format!(
                    "text with space {}normalized",
                    text_not(*normalize_whitespace),
                ),
                html,
            ),
            AttributeKind::StringList { input_separator } => softpre.format(
                &format!("list with items separated by {input_separator:?}",),
                html,
            ),
        }
    }
}

/// Whether an index should be created
#[derive(Debug, PartialEq, Clone, Copy)]
enum AttributeIndexing {
    Index {
        /// Whether only the first word of each item should be used
        /// for indexing (useful for package names given with version
        /// number after it, to index the package name without the
        /// version).
        first_word_only: bool,
        /// Whether to convert the user-given values to lowercase for
        /// the index
        use_lowercase: bool,
    },
    NoIndex,
}

impl AttributeIndexing {
    fn key_string_preparation(&self) -> Option<KeyStringPreparation> {
        match *self {
            AttributeIndexing::Index {
                first_word_only,
                use_lowercase,
            } => Some(KeyStringPreparation {
                first_word_only,
                use_lowercase,
            }),
            AttributeIndexing::NoIndex => None,
        }
    }
    fn to_html(&self, is_list: bool, html: &HtmlAllocator) -> Result<AId<Node>> {
        let softpre = SoftPre::default();
        match self {
            AttributeIndexing::Index {
                first_word_only,
                use_lowercase,
            } => softpre.format(
                &format!(
                    "{}{}indexed,\n{}lower-cased",
                    if *first_word_only {
                        "first word "
                    } else {
                        "full value "
                    },
                    if is_list { "of each item " } else { "" },
                    text_not(*use_lowercase)
                ),
                html,
            ),
            AttributeIndexing::NoIndex => html.text(format!("not indexed")),
        }
    }
}

/// All metainformation on an attribute (its name, format, indexing
/// requirements..).
#[derive(Debug)]
struct AttributeSpecification {
    key: AttributeName,
    need: AttributeNeed,
    kind: AttributeKind,
    /// Whether to automatically find http and https URLs in the
    /// text and create links with them (i.e. the string `"See
    /// https://example.com."` is turned into the HTML code `See
    /// <a href="https://example.com">https://example.com</a>.`)
    autolink: bool,
    indexing: AttributeIndexing,
}

impl AttributeSpecification {
    const TITLES: &[&str] = &[
        "Name",
        "Content needed?",
        "Content kind",
        "URLs automatically linked?",
        "Indexing",
    ];

    /// Show the specification using HTML markup, for writing to
    /// ATTRIBUTE_SPECIFICATION_FILENAME.
    fn to_html(&self, html: &HtmlAllocator) -> Result<AId<Node>> {
        let AttributeSpecification {
            key,
            need,
            kind,
            autolink,
            indexing,
        } = self;
        html.tr(
            [],
            [
                html.td([], html.i([], html.text(key.as_ref())?)?)?,
                html.td(
                    [],
                    html.text(match need {
                        AttributeNeed::Optional => "optional",
                        AttributeNeed::Required => "required",
                    })?,
                )?,
                html.td([], kind.to_html(html)?)?,
                html.td([], html.text(if *autolink { "yes" } else { "no" })?)?,
                html.td([], indexing.to_html(kind.is_list(), html)?)?,
            ],
        )
    }
}

fn specifications_to_html(html: &HtmlAllocator) -> Result<AId<Node>> {
    let head: Vec<_> = AttributeSpecification::TITLES
        .iter()
        .map(|s| html.td([att("bgcolor", "#e0e0e0")], html.text(s)?))
        .collect::<Result<_>>()?;
    let mut body = html.new_vec();
    for spec in METADATA_SPECIFICATION {
        body.push(spec.to_html(html)?)?;
    }
    html.table(
        [att("border", 1)],
        [html.thead([], html.tr([], head)?)?, html.tbody([], body)?],
    )
}

/// Description of the metadata attributes, what they must contain,
/// and how they are indexed. The order of entries here is also the
/// same order used for showing the extracted info in the info boxes
/// in the index pages.
const METADATA_SPECIFICATION: &[AttributeSpecification] = {
    &[
        AttributeSpecification {
            key: AttributeName("Keywords"),
            need: AttributeNeed::Required,
            kind: AttributeKind::StringList {
                input_separator: ",",
            },
            autolink: true,
            indexing: AttributeIndexing::Index {
                first_word_only: false,
                use_lowercase: true,
            },
        },
        AttributeSpecification {
            key: AttributeName("Version"),
            need: AttributeNeed::Required,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::Index {
                first_word_only: false,
                use_lowercase: false,
            },
        },
        AttributeSpecification {
            key: AttributeName("Packages"),
            need: AttributeNeed::Required,
            kind: AttributeKind::StringList {
                input_separator: ",",
            },
            autolink: true,
            indexing: AttributeIndexing::Index {
                first_word_only: true,
                use_lowercase: false,
            },
        },
        AttributeSpecification {
            key: AttributeName("Description"),
            need: AttributeNeed::Optional,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::NoIndex,
        },
        AttributeSpecification {
            key: AttributeName("Comments"),
            need: AttributeNeed::Optional,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::NoIndex,
        },
        AttributeSpecification {
            key: AttributeName("Citation"),
            need: AttributeNeed::Optional,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::NoIndex,
        },
        AttributeSpecification {
            key: AttributeName("DOI"),
            need: AttributeNeed::Optional,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::Index {
                first_word_only: false,
                use_lowercase: false,
            },
        },
        AttributeSpecification {
            key: AttributeName("Contact"),
            need: AttributeNeed::Required,
            kind: AttributeKind::String {
                normalize_whitespace: false,
            },
            autolink: true,
            indexing: AttributeIndexing::Index {
                first_word_only: false,
                use_lowercase: false,
            },
        },
    ]
};

// `lazy_static` sets things up so that the data for the given
// constant (`METADATA_KEY_POSITION`) is calculated when it is read
// for the first time.
lazy_static! {
    /// A mapping from an attribute name to its position; used for
    /// sorting the user-provided metadata entries uniformly.
    static ref METADATA_KEY_POSITION: BTreeMap<AttributeName, usize> = METADATA_SPECIFICATION
        .iter()
        .enumerate()
        .map(|(i, spec)| (spec.key, i))
        .collect();
}

// =============================================================================
// Data structures to hold an attribute value, and the whole set of
// values for a file after their extraction from it, as well as
// operations (`impl` blocks) including parsing that information from
// strings and formatting the information as HTML.

/// A concrete attribute value: either a string, a list of strings, or
/// not present. It links the `AttributeSpecification` so that it can
/// be properly formatted and generate links back to the correct
/// index.
#[derive(Debug)]
struct AttributeValue {
    spec: &'static AttributeSpecification,
    value: AttributeValueKind,
}

#[derive(Debug)]
enum AttributeValueKind {
    String(String),
    StringList(Vec<String>),
    NA,
}

impl AttributeValue {
    /// Parse an input into the representation required by the given
    /// AttributeSpecification (like, a single string or
    /// lists). Returns an error if it couldn't do that, which happens
    /// if the input is only whitespace but a value is required by the
    /// spec.
    fn from_str_and_spec(val: &str, spec: &'static AttributeSpecification) -> Result<Self> {
        let value: AttributeValueKind = if val.is_empty() || val == "NA" {
            match spec.need {
                AttributeNeed::Optional => AttributeValueKind::NA,
                AttributeNeed::Required => {
                    bail!(
                        "attribute {:?} requires {}, but none given",
                        spec.key,
                        if spec.kind.is_list() {
                            "values"
                        } else {
                            "a value"
                        }
                    )
                }
            }
        } else {
            match spec.kind {
                AttributeKind::String {
                    normalize_whitespace,
                } => {
                    let value = val.trim();
                    let value = if normalize_whitespace {
                        util::normalize_whitespace(value)
                    } else {
                        value.into()
                    };
                    AttributeValueKind::String(value)
                }
                AttributeKind::StringList { input_separator } => {
                    // (Note: there is no need to replace '\n' with ' '
                    // in `val` first, because the trim will remove
                    // those around values, and normalize_whitespace will
                    // replace those within keys, too.)
                    let vals: Vec<String> = val
                        .split(input_separator)
                        .map(|s| util::normalize_whitespace(s.trim()))
                        .filter(|s| !s.is_empty())
                        .collect();
                    if vals.is_empty() {
                        match spec.need {
                            AttributeNeed::Optional => AttributeValueKind::NA,
                            AttributeNeed::Required => {
                                bail!(
                                    "values for attribute {:?} are required but missing",
                                    spec.key
                                )
                            }
                        }
                    } else {
                        AttributeValueKind::StringList(vals)
                    }
                }
            }
        };
        Ok(AttributeValue { spec, value })
    }

    /// Also works for single-value and unavailable attributes,
    /// returning a list of one or no entries, respectively. (`Cow`
    /// allows both sharing of existing vectors as well as holding new
    /// ones; that's just a performance feature, they can be used
    /// wherever a Vec or [] is required.)
    fn as_string_list(&self) -> Cow<[String]> {
        match &self.value {
            AttributeValueKind::StringList(value) => Cow::from(value.as_slice()),
            AttributeValueKind::NA => Cow::from(&[]),
            AttributeValueKind::String(value) => Cow::from(vec![value.clone()]),
        }
    }

    /// Convert the value, or whole value list in the case of
    /// StringList, to HTML. This is used for the file info boxes for
    /// both .html and .md files. An `ASlice<Node>` is a list of
    /// elements (nodes), directly usable as the body (child elements)
    /// for another element.
    fn to_html(&self, html: &HtmlAllocator) -> Result<AId<Node>> {
        let AttributeValue { spec, value } = self;
        // Make a function `possibly_link` that takes the raw
        // `key_value` string and the prepared value and wraps the
        // latter with a link to the index for `spec`key`, to the
        // entry for `key_value`, if the spec says it is indexed
        // (otherwise just wrap the body in a `<div>` element).
        let possibly_link = {
            let key_string_preparation = spec.indexing.key_string_preparation();
            move |key_value, body| {
                if let Some(key_string_preparation) = &key_string_preparation {
                    let anchor_name = spec
                        .key
                        .anchor_name(&key_string_preparation.prepare_key_string(key_value));
                    html.a([att("href", format!("#{anchor_name}"))], body)
                } else {
                    html.div([], body)
                }
            }
        };
        match value {
            AttributeValueKind::String(value) => {
                let softpre = SoftPre {
                    tabs_to_nbsp: Some(8),
                    autolink: spec.autolink,
                    input_line_separator: "\n",
                };
                let body = softpre.format(value, html)?.to_aslice(html)?;
                possibly_link(value, body)
            }
            AttributeValueKind::StringList(value) => {
                let mut body = html.new_vec();
                let mut need_comma = false;
                for text in value {
                    if need_comma {
                        body.push(html.text(", ")?)?;
                    }
                    need_comma = true;
                    // Do not do SoftPre for string list items, but only
                    // autolink (if requested). Then wrap in <q></q>.
                    let text_marked_up = if spec.autolink {
                        ahtml::util::autolink(html, text)?
                    } else {
                        html.text_slice(text)?
                    };
                    body.push(html.q([], possibly_link(text, text_marked_up)?)?)?;
                }
                html.div([], body)
            }
            AttributeValueKind::NA => html.i([], html.text("n.A.")?),
        }
    }
}

/// The concrete metadata values for one particular file, specified
/// via XML comments in it. The keys are the same as (or a subset of)
/// those in `METADATA_SPECIFICATION`.
#[derive(Debug)]
struct Metadata(BTreeMap<AttributeName, AttributeValue>);

impl Metadata {
    /// Retrieve the value for an attribute name.
    fn get(&self, key: AttributeName) -> Option<&AttributeValue> {
        self.0.get(&key).or_else(|| {
            if list_get_by_key(METADATA_SPECIFICATION, |spec| &spec.key, &key).is_none() {
                panic!("invalid AttributeName value {key:?}")
            }
            None
        })
    }

    /// The entries in the same order as given in
    /// `METADATA_SPECIFICATION`, with gaps where a key wasn't given
    /// in the file.
    fn sorted_entries(&self) -> Vec<(AttributeName, Option<&AttributeValue>)> {
        let mut result: Vec<_> = METADATA_SPECIFICATION
            .iter()
            .map(|spec| (spec.key, None))
            .collect();
        for (key, attval) in &self.0 {
            let i = METADATA_KEY_POSITION[key];
            result[i].1 = Some(attval);
        }
        result
    }

    /// An HTML table with all metadata.
    fn to_html(&self, html: &HtmlAllocator) -> Result<AId<Node>> {
        let mut table_body = html.new_vec();
        for (attribute_name, opt_attval) in self.sorted_entries() {
            let attval_html = if let Some(attval) = opt_attval {
                attval.to_html(html)?
            } else {
                // Entry is missing in the file; show that fact.
                // (Also report that top-level as a warning? That
                // would be a bit ugly to implement.)
                html.i(
                    [
                        att("style", "color: red;"),
                        att(
                            "title",
                            format!(
                                "The XML comment for {attribute_name:?} is completely \
                                 missing in this file, perhaps because of an oversight."
                            ),
                        ),
                    ],
                    html.text("entry missing")?,
                )?
            };
            table_body.push(html.tr(
                [],
                [
                    html.td(
                        [
                            att("class", "metadata_key"),
                            // The above CSS is lost via Markdown, thus also try:
                            att("valign", "top"),
                            att("align", "right"),
                        ],
                        html.i([], [html.text(attribute_name.as_ref())?, html.text(":")?])?,
                    )?,
                    html.td([att("class", "metadata_value")], attval_html)?,
                ],
            )?)?;
        }
        html.table([att("class", "metadata"), att("border", 0)], table_body)
    }
}

/// The whole, concrete, information on one particular file.
#[derive(Debug)]
struct FileInfo {
    id: usize,
    path: BaseAndRelPath,
    metadata: Metadata,
}

// For FileInfo to go into a BTreeSet (`BTreeSet<&FileInfo>` further
// below), it needs to be orderable. Only `id` is relevant for that
// (and the other types have no Ord implementation), thus write
// implementations manually:
impl Ord for FileInfo {
    fn cmp(&self, other: &Self) -> std::cmp::Ordering {
        self.id.cmp(&other.id)
    }
}
impl PartialOrd for FileInfo {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        Some(self.cmp(other))
    }
}
impl PartialEq for FileInfo {
    fn eq(&self, other: &Self) -> bool {
        self.id == other.id
    }
}
impl Eq for FileInfo {}

impl FileInfo {
    /// Show in a box with a table of the metadata
    fn to_info_box_html(
        &self,
        html: &HtmlAllocator,
        id_prefix: &str,
        file_path_or_name: &str,
    ) -> Result<AId<Node>> {
        let id_string = format!("{id_prefix}-{}", self.id);
        html.a(
            [att("name", &id_string)],
            html.table(
                [
                    att("id", &id_string),
                    att("class", "fileinfo"),
                    att("border", 0),
                ],
                [
                    html.tr(
                        [],
                        html.td(
                            [
                                att("class", "fileinfo_path"),
                                att("bgcolor", FILEINFO_PATH_BGCOLOR),
                            ],
                            html.b(
                                [],
                                html.a(
                                    [
                                        att(
                                            "href",
                                            // (This would need path
                                            // calculation if the index files
                                            // weren't written to the
                                            // top-level directory)
                                            self.path.rel_path(),
                                        ),
                                        att("title", "Open the file"),
                                    ],
                                    [
                                        html.text(file_path_or_name)?,
                                        html.nbsp()?,
                                        document_symbol(html)?,
                                    ],
                                )?,
                            )?,
                        )?,
                    )?,
                    html.tr(
                        [att("class", "fileinfo_metadata")],
                        html.td(
                            [att("bgcolor", FILEINFO_METADATA_BGCOLOR)],
                            self.metadata.to_html(html)?,
                        )?,
                    )?,
                ],
            )?,
        )
    }
}

// =============================================================================
// An abstraction of document sections:
//
// * that can be formatted for an HTML file or for a Markdown file
//   with embedded HTML;
// * that a table of contents can be built from (showing and linking the
//   (possibly nested) subsections).

/// A section consists of a (optional) section title, an optional
/// intro (that could be the only content), and a list of subsections
/// which could be empty. The toplevel section will not have a title,
/// but just a list of subsections. If `in_red` is true, will show the
/// title in red if possible.
struct Section {
    in_red: bool,
    title: Option<String>,
    intro: Option<SerHtmlFrag>,
    subsections: Vec<Section>,
}

/// A list of section numbers (like "1.3.2") to identify a particular
/// subsection, used for naming them and linking from the table of
/// contents.
struct NumberPath {
    numbers: Vec<usize>,
}

impl NumberPath {
    fn empty() -> Self {
        Self {
            numbers: Vec::new(),
        }
    }
    /// Make a new path by adding an id to the end of the current one.
    fn add(&self, number: usize) -> Self {
        let mut numbers = self.numbers.clone();
        numbers.push(number);
        Self { numbers }
    }
    /// Gives e.g. `3` for a 3-level deep path
    fn level(&self) -> usize {
        self.numbers.len()
    }
    /// Gives e.g. `"1.3.2"`
    fn to_string(&self) -> String {
        self.numbers
            .iter()
            .map(|number| format!("{number}"))
            .collect::<Vec<String>>()
            .join(".")
    }
}

impl Section {
    /// Build a table of contents
    fn to_toc_html(&self, number_path: NumberPath, html: &HtmlAllocator) -> Result<AId<Node>> {
        let title_node = if let Some(title) = &self.title {
            let number_path_string = number_path.to_string();
            let section_id = format!("section-{number_path_string}");
            html.a(
                [
                    att("class", "toc_entry"),
                    if self.in_red {
                        att("style", "color: red;")
                    } else {
                        None
                    },
                    att("href", format!("#{section_id}")),
                ],
                html.text(format!("{number_path_string} {title}"))?,
            )?
        } else {
            html.empty_node()?
        };
        let mut sub_nodes = html.new_vec();
        for (i, section) in self.subsections.iter().enumerate() {
            let id = i + 1;
            let sub_path = number_path.add(id);
            sub_nodes.push(section.to_toc_html(sub_path, html)?)?;
        }
        html.dl([], [html.dt([], title_node)?, html.dd([], sub_nodes)?])
    }

    /// Format the section for the inclusion in an HTML file
    fn to_html(&self, number_path: NumberPath, html: &HtmlAllocator) -> Result<ASlice<Node>> {
        let mut vec = html.new_vec();
        if let Some(title) = &self.title {
            // Choose the html method for the current nesting level by
            // indexing into the list of them, referring to the
            // methods via function reference syntax
            // (e.g. `html.h2(..)` has to be called right away,
            // `html.h2` alone is not valid, but `HtmlAllocator::h2`
            // gets a reference to the h2 method without calling it,
            // but it is now actually a reference to a normal
            // function, hence further down, `element` has to be
            // called with `html` as a normal function argument
            // instead).
            let elements = [
                HtmlAllocator::h1,
                HtmlAllocator::h2,
                HtmlAllocator::h3,
                HtmlAllocator::h4,
                HtmlAllocator::h5,
                HtmlAllocator::h6,
            ];
            let mut level = number_path.level();
            let max_level = elements.len() - 1;
            if level > max_level {
                level = max_level;
            }
            let element = elements[level];

            let number_path_string = number_path.to_string();
            let section_id = format!("section-{number_path_string}");
            vec.push(html.a([att("name", &section_id)], [])?)?;
            vec.push(element(
                html,
                [
                    att("id", section_id),
                    if self.in_red {
                        att("style", "color: red;")
                    } else {
                        None
                    },
                ],
                // Prefix the path to the title; don't try to use CSS
                // as it won't make it through Markdown.
                html.text(format!("{number_path_string} {title}"))?,
            )?)?;
        }

        if let Some(fragment) = &self.intro {
            vec.push(html.preserialized(fragment.clone())?)?;
        }

        for (i, section) in self.subsections.iter().enumerate() {
            let id = i + 1;
            let sub_path = number_path.add(id);
            vec.push(html.div([], section.to_html(sub_path, html)?)?)?;
        }

        Ok(vec.as_slice())
    }

    /// Format the section for the inclusion in a markdown file
    fn to_markdown(&self, number_path: NumberPath) -> Result<StringTree> {
        let mut title_and_intro = String::new();
        if let Some(title) = &self.title {
            let number_path_string = number_path.to_string();
            let section_id = format!("section-{number_path_string}");
            let mut num_hashes = number_path.level() + 1;
            if num_hashes > 6 {
                num_hashes = 6
            }
            for _ in 0..num_hashes {
                title_and_intro.push('#');
            }
            title_and_intro.push(' ');
            // Add an anchor for in-page links; use both available
            // approaches, the older "name" and the newer "id"
            // approach, hoping that at least one gets through
            // GitLab's formatting.
            let html = HTML_ALLOCATOR_POOL.get();
            title_and_intro.push_str(
                &html
                    .a([att("name", &section_id), att("id", &section_id)], [])?
                    .to_html_fragment_string(&html)?,
            );
            title_and_intro.push_str(&number_path_string);
            title_and_intro.push(' ');
            // Should we use HTML to try to make this red if
            // `self.in_red`? But GitLab drops it anyway, and there's
            // risk of messing up the title display.
            title_and_intro.push_str(title);
            title_and_intro.push_str("\n\n");
        }

        if let Some(fragment) = &self.intro {
            title_and_intro.push_str(fragment.as_str());
            title_and_intro.push_str("\n\n");
        }

        let sub_trees = self
            .subsections
            .par_iter()
            .enumerate()
            .map(|(i, section)| {
                let id = i + 1;
                let sub_path = number_path.add(id);
                section.to_markdown(sub_path)
            })
            .collect::<Result<_>>()?;

        Ok(StringTree::Branching(vec![
            StringTree::Leaf(title_and_intro),
            StringTree::Branching(sub_trees),
        ]))
    }
}

// =============================================================================
/// An abstraction for folders and files, to collect the paths
/// reported by Git into, and then to map to nested
/// `Section`s. Contained files/folders are stored sorted by the name
/// of the file/folder inside this Folder; files and folders are
/// stored in separate struct fields, because their formatting will
/// also end up separately in a `Section` (files go to the intro,
/// folders to the subsections).
struct Folder<'f> {
    files: BTreeMap<String, &'f FileInfo>,
    folders: BTreeMap<String, Folder<'f>>,
}

impl<'f> Folder<'f> {
    fn new() -> Self {
        Self {
            files: BTreeMap::new(),
            folders: BTreeMap::new(),
        }
    }

    // This is just a helper method that recursively calls itself; see
    // `add` for the relevant wrapper method.
    fn add_(&mut self, segments: &[&str], file: &'f FileInfo) -> Result<()> {
        match segments {
            [] => unreachable!(),
            [segment, rest @ ..] => {
                if rest.is_empty() {
                    // `segment` being the last of the segments means
                    // that it represents the file name of the XML
                    // file itself
                    if let Some(oldfile) = self.files.get(*segment) {
                        bail!("duplicate file: {file:?} already entered as {oldfile:?}")
                    } else {
                        self.files.insert(segment.to_string(), file);
                    }
                } else {
                    if let Some(folder) = self.folders.get_mut(*segment) {
                        folder.add_(rest, file)?;
                    } else {
                        let mut folder = Folder::new();
                        folder.add_(rest, file)?;
                        self.folders.insert(segment.to_string(), folder);
                    }
                }
            }
        }
        Ok(())
    }

    /// Add a `FileInfo` to the right place in the `Folder` hierarchy
    /// according to the `FileInfo`'s `rel_path`, which is split into
    /// path segments.
    fn add(&mut self, file: &'f FileInfo) -> Result<()> {
        let segments: Vec<&str> = file.path.rel_path().split('/').collect();
        self.add_(&segments, file)
    }

    /// Convert to nested `Section`s.
    fn to_section(&self, title: Option<String>) -> Result<Section> {
        let intro = {
            let html = HTML_ALLOCATOR_POOL.get();

            // Create and then fill in a vector of boxes which we'll use
            // as the body for a `div` HTML element; this vector is a
            // custom vector implementation that allocates its storage
            // space from the `HtmlAllocator` in `html`, that's why we
            // allocate it via the `new_vec` method and not via
            // `Vec::new()`.
            let mut file_info_boxes = html.new_vec();
            for (file_name, file_info) in &self.files {
                file_info_boxes.push(file_info.to_info_box_html(&html, "box", file_name)?)?;
            }
            Some(html.preserialize(html.div([], file_info_boxes)?)?)
        };

        let subsections = self
            .folders
            .par_iter()
            .map(|(folder_name, folder)| {
                // Append a '/' to folder_name to indicate that those are
                // folder names
                folder.to_section(Some(format!("{folder_name}/")))
            })
            .collect::<Result<_>>()?;

        Ok(Section {
            in_red: false,
            title,
            intro,
            subsections,
        })
    }
}

// =============================================================================
// Error reporting: this program does not stop but continues
// processing when it encounters errors, collecting them and then in
// the end reporting them all (both on the command line and in the
// output page).

/// An error report with all errors that happened while processing one
/// particular file.
#[derive(Debug)]
struct FileErrors {
    path: BaseAndRelPath,
    errors: Vec<String>,
}

impl FileErrors {
    /// Returns `<dt>..<dd>..` (definition term / definition data)
    /// pairs to be used in a `<dl>..</dl>` (definition list).
    fn to_html(&self, html: &HtmlAllocator) -> Result<Flat<Node>> {
        const SOFT_PRE: SoftPre = SoftPre {
            tabs_to_nbsp: Some(4),
            autolink: true,
            input_line_separator: "\n",
        };
        let mut ul_body = html.new_vec();
        for error in &self.errors {
            ul_body.push(html.li([], SOFT_PRE.format(error, html)?)?)?;
        }
        let dt = html.dt(
            [],
            [
                html.text("For ")?,
                html.a(
                    [att("href", self.path.rel_path())],
                    html.text(self.path.rel_path())?,
                )?,
                html.text(":")?,
            ],
        )?;
        let dd = html.dd([], html.ul([], ul_body)?)?;
        Ok(Flat::Two(dt, dd))
    }

    /// Print as plaintext, for error reporting to stderr.
    fn print_plain<O: Write>(&self, out: &mut O) -> Result<()> {
        writeln!(out, "    For {:?}:", self.path.rel_path())?;
        for error in &self.errors {
            let lines: Vec<&str> = error.split('\n').collect();
            writeln!(out, "      * {}", lines[0])?;
            for line in &lines[1..] {
                writeln!(out, "        {}", line)?;
            }
        }
        Ok(())
    }
}

// =============================================================================
// Parsing and printing functionality, up to and including the
// `build_index` function below.

/// Parse all XML comments from above the first XML opening element
/// out of one file as `Metadata`. The comments are passed as an
/// iterator over `XMLDocumentComment`, which has the string and
/// location of the comment. The `XMLDocumentComment` has a limited
/// lifetime (validity span) indicated by the context of the call to
/// `parse_comments`, hence passed as lifetime parameter 'a;
fn parse_comments<'a>(
    comments: impl Iterator<Item = XMLDocumentComment<'a>>,
) -> Result<Metadata, Vec<String>> {
    let spec_by_lowercase_key: BTreeMap<String, &AttributeSpecification> = METADATA_SPECIFICATION
        .iter()
        .map(|spec| (spec.key.as_ref().to_lowercase(), spec))
        .collect();
    let mut unseen_specs_by_lowercase_key = spec_by_lowercase_key.clone();
    let mut map: BTreeMap<AttributeName, AttributeValue> = BTreeMap::new();

    // Collect all errors instead of stopping at the first one.
    let mut errors: Vec<String> = Vec::new();
    for comment in comments {
        // Using a function without arguments and calling it right
        // away to capture the result (Ok or Err).
        let result = (|| {
            if let Some((key_, value)) = comment.string.split_once(":") {
                let lc_key = key_.trim().to_lowercase();
                let value = value.trim();

                if let Some(spec) = spec_by_lowercase_key.get(&lc_key) {
                    unseen_specs_by_lowercase_key.remove(&lc_key);
                    if map.contains_key(&spec.key) {
                        bail!("duplicate entry for attribute name {lc_key:?}")
                    } else {
                        let value = AttributeValue::from_str_and_spec(value, spec)?;
                        map.insert(spec.key, value);
                    }
                } else {
                    bail!("unknown attribute name {lc_key:?} given")
                }
            } else {
                bail!("comment does not start with a keyword name and ':'")
            }
            Ok(())
        })()
        .with_context(|| anyhow!("XML comment on {}", comment.location));
        if let Err(e) = result {
            errors.push(format!("{e:#}"));
        }
    }

    let missing: Vec<AttributeName> = unseen_specs_by_lowercase_key
        .into_values()
        .filter_map(|spec| {
            // Do not report as missing if it's optional
            if spec.need == AttributeNeed::Optional {
                None
            } else {
                Some(spec.key)
            }
        })
        .collect();
    if !missing.is_empty() {
        // Show just the names, not the AttributeName wrappers
        errors.push(format!(
            "attributes with these names are missing: {}",
            format_string_list(&missing),
        ));
    }

    if errors.is_empty() {
        Ok(Metadata(map))
    } else {
        Err(errors)
    }
}

/// Settings and a method for the conversion of a value (string) into
/// the key string to be used in an index entry (e.g. an item of
/// `Packages` like "BDSKY 1.2.3" might be converted to "BDSKY", or a
/// `Keywords` entry "Sampling-through-time" to
/// "sampling-through-time").
struct KeyStringPreparation {
    first_word_only: bool,
    use_lowercase: bool,
}

impl KeyStringPreparation {
    fn prepare_key_string(&self, key_string: &str) -> String {
        let normalized = util::normalize_whitespace(key_string.trim());
        // ^ Should we keep newlines instead, and then SoftPre for the
        // display? Probably not.
        let part = if self.first_word_only {
            normalized
                .split(' ')
                .next()
                .expect("key_string is not empty")
        } else {
            &normalized
        };
        if self.use_lowercase {
            part.to_lowercase()
        } else {
            part.into()
        }
    }
}

/// Build an index over all files for one particular attribute name (`attribute_key`).
fn build_index_section(
    attribute_key: AttributeName,
    key_string_normalization: KeyStringPreparation,
    file_infos: &[FileInfo],
) -> Result<Section> {
    // Build an index by the value for attribute_key (lower-casing the
    // key values for consistency if use_lowercase is true). The index
    // maps from key value to a set of all `FileInfo`s for that
    // value. The BTreeMap keeps the key values sorted alphabetically,
    // which is nice so we don't have to sort those afterwards.
    let mut file_infos_by_key_string: BTreeMap<String, BTreeSet<&FileInfo>> = BTreeMap::new();

    for file_info in file_infos {
        if let Some(attribute_value) = file_info.metadata.get(attribute_key) {
            for key_string in attribute_value.as_string_list().iter() {
                file_infos_by_key_string.insert_value(
                    key_string_normalization.prepare_key_string(key_string),
                    file_info,
                );
            }
        }
    }

    let html = HTML_ALLOCATOR_POOL.get();

    // The contents of the section, i.e. the list of all key_strings and
    // the files for the respective key_string.
    let mut body = html.new_vec();
    for (key_string, file_infos) in &file_infos_by_key_string {
        // Output the key value, with an anchor
        let anchor_name = attribute_key.anchor_name(key_string);
        body.push(html.dt(
            // The first list passed to HTML constructor methods like
            // `dt` is holding attributes, the second the child
            // elements (but a single child element can also be passed
            // without putting it into a list). The `?` is needed to
            // handle errors, because those method calls can fail,
            // either when they detect nesting of HTML elements that
            // doesn't conform to the HTML standard, or when the
            // allocator is running against the allocation limit that
            // was provided to `HtmlAllocator::new`.
            [att("class", "key_dt")],
            html.strong(
                [att("class", "key")],
                html.i(
                    [],
                    html.q(
                        [],
                        html.a(
                            [att("name", &anchor_name), att("id", &anchor_name)],
                            html.text(key_string)?,
                        )?,
                    )?,
                )?,
            )?,
        )?)?;

        // Output all the files for that key value, sorted by path.
        let mut sorted_file_infos: Vec<&FileInfo> = file_infos.iter().copied().collect();
        sorted_file_infos.sort_by_key(|fileinfo| fileinfo.path.full_path());
        let mut dd_body = html.new_vec();
        for file_info in sorted_file_infos {
            // Show the path, and link to the actual XML file, but
            // also provide a link to the box with the extracted
            // metainfo further up the page.
            let rel_path = file_info.path.rel_path();
            let path_with_two_links_html = html.div(
                [att("class", "file_link")],
                [
                    html.a(
                        [
                            att("href", format!("#box-{}", file_info.id)),
                            att("title", "Jump to info box"),
                        ],
                        html.text(rel_path)?,
                    )?,
                    html.nbsp()?,
                    html.a(
                        [att("href", rel_path), att("title", "Open the file")],
                        document_symbol(&html)?,
                    )?,
                ],
            )?;

            dd_body.push(path_with_two_links_html)?;
        }
        body.push(html.dd(
            [att("class", "key_dd")],
            html.div([att("class", "key_dd")], dd_body)?,
        )?)?;
    }

    Ok(Section {
        in_red: false,
        title: Some(attribute_key.as_ref().into()),
        intro: Some(html.preserialize(html.dl([att("class", "key_dl")], body)?)?),
        subsections: vec![],
    })
}

/// Create a `<div>&nbsp;<br>...</div>` occupying some amount of
/// whitespace; useful at the end of the document to ensure that
/// document-internal links (e.g. from the table of contents) always
/// allows the document to be moved so that the link target is at the
/// top of the window.
fn empty_space_element(number_of_br_elements: usize, html: &HtmlAllocator) -> Result<AId<Node>> {
    let mut brs = html.new_vec();
    for _ in 0..number_of_br_elements {
        brs.push(html.nbsp()?)?;
        brs.push(html.br([], [])?)?;
    }
    html.div([], brs)
}

const FILEINFO_PATH_BGCOLOR: &str = "#cec7f2";
const FILEINFO_METADATA_BGCOLOR: &str = "#e3e7ff";

/// CSS style information; only useful for the .html file, not
/// included in the .md file as GitLab will ignore it anyway when
/// formatting that file.
fn css_styles() -> String {
    [
        "
/* make sections/subsections stand out more */
h2 {
  margin-top: 40px;
}

h3 {
  border-bottom: 2px solid #407cd9;
  margin-top: 40px;
}

/* a TABLE */
.fileinfo {
  border-spacing: 0px;
  margin-bottom: 20px; /* should instead use a grid something so that fileinfo is reusable */
}
/* a TD */
.fileinfo_path {
  background-color: ",
        FILEINFO_PATH_BGCOLOR,
        ";
  font-weight: bold;
}
/* a TR */
.fileinfo_metadata {
  background-color: ",
        FILEINFO_METADATA_BGCOLOR,
        ";
}
/* a TD */
.metadata_key {
  vertical-align: top;
  text-align: right;
  font-style: italic;
  padding-right: 6px;
  padding-left: 2px;
  padding-top: 2px;
  padding-bottom: 2px;
}
/* a TD */
.metadata_value {
  padding: 2px;
}
.key_dl {
}
.key_dt {
  margin-top: 1.5em;
  margin-bottom: 0.8em;
}
.key_dd {
}
/* a STRONG */
.key {
}
/* a DIV */
.file_link {
}
",
    ]
    .join("")
}

/// Make an intro, slightly differently depending on whether it is
/// for the .md or .html file.
fn make_intro(making_md: bool, html: &HtmlAllocator) -> Result<AId<Node>> {
    html.div(
        [],
        [
            html.p(
                [],
                html.text(
                    "Welcome to the cEVO XML hub! This is a shared internal (private) \
                     repository for uploading XML files for BEAST2.",
                )?,
            )?,
            html.p(
                [],
                [
                    html.text("To contribute XML files, see ")?,
                    html.a(
                        [att("href", format!("{CONTRIBUTE_FILENAME}.md"))],
                        html.text(CONTRIBUTE_FILENAME)?,
                    )?,
                    html.text(".")?,
                ],
            )?,
            html.p(
                [],
                [
                    html.text("This is an index over all XML files, generated by ")?,
                    html.a(
                        [att("href", SOURCE_CHECKOUT.supposed_upstream_web_url)],
                        html.text(REPO_NAME)?,
                    )?,
                    html.text(".")?,
                ],
            )?,
            html.p(
                [],
                [
                    html.text(
                        "From the index, click on a link to jump to the info box \
                     about that file, or on the ",
                    )?,
                    document_symbol(html)?,
                    html.text(" symbol to open the XML file directly.")?,
                ],
            )?,
            html.p(
                [],
                [html.text(
                    "You can also search the contents of all files via the \
                     GitLab search form, which you can find towards the top left \
                     corner of this page (the input field saying \"Search or go \
                     to...\").",
                )?],
            )?,
            if making_md {
                html.p(
                    [],
                    html.small(
                        [],
                        html.text(format!(
                            "Note: if you \"git clone\" this repository, open the file \
                             {:?} instead, it has the same info already \
                             formatted as HTML (and in fact has better formatting than \
                             the view you're seeing here).",
                            HTML_FILE.path_from_repo_top
                        ))?,
                    )?,
                )?
            } else {
                html.empty_node()?
            },
        ],
    )
}

// Helpers for the varous check_dry_run macros. Do not actually use
// `eprintln!` since that can panic.
fn eprintln_dry_run(s: String) {
    _ = writeln!(&mut stderr(), "+ --dry-run: would run: {s}");
}
fn eprintln_running(s: String) {
    _ = writeln!(&mut stderr(), "+ running: {s}");
}

/// Run one conversion from the XML files to the index files. Returns
/// the exit code to exit the program with.
fn build_index(
    global_opts: &Opts,
    build_opts: &BuildOpts,
    base_path: &Path,
    git_log_version_checker: &GitLogVersionChecker,
    xmlhub_checkout: &CheckedCheckoutContext1<&PathBuf>,
    maybe_checked_xmlhub_checkout: &Option<CheckedCheckoutContext2<&PathBuf>>,
) -> Result<i32> {
    // Define a macro to only run $body if opts.dry_run is false,
    // otherwise show $message instead, or show $message anyway if
    // opts.verbose.
    macro_rules! check_dry_run {
        { message: $message:expr, $body:expr } => {
            let s = || -> String { $message.into() };
            if global_opts.dry_run {
                eprintln_dry_run(s());
            } else {
                if global_opts.verbose {
                    eprintln_running(s());
                }
                $body;
            }
        }
    }

    // Update repository if requested
    if let Some(checked_xmlhub_checkout) = maybe_checked_xmlhub_checkout {
        if build_opts.pull {
            check_dry_run! {
                message: "git pull",
                if !git(base_path, &["pull"], global_opts.quiet)? {
                    bail!("git pull failed")
                }
            }
        }

        if build_opts.batch {
            let default_remote = &checked_xmlhub_checkout.default_remote;

            check_dry_run! {
                message: format!("git remote update {default_remote:?}"),
                if !git(base_path, &["remote", "update", default_remote],
                        global_opts.quiet)? {
                    bail!("git remote update {default_remote:?} failed")
                }
            }

            let remote_banch_reference = checked_xmlhub_checkout.remote_branch_reference();

            check_dry_run! {
                message: format!("git reset --hard {remote_banch_reference:?}"),
                if !git(base_path, &["reset", "--hard", &remote_banch_reference],
                        global_opts.quiet)? {
                    bail!("git reset --hard {remote_banch_reference:?} failed")
                }
            }
        }
    }

    // Get the list of files in the Git repo given by the base_path
    // option. Collect them as a vector of `RelPathWithBase` values,
    // each of which carries both a path to a base directory
    // (optional) and a relative path from there (if it contains no
    // base directory, the current working directoy is the base).
    let paths: Vec<BaseAndRelPath> = {
        if !global_opts.no_version_check {
            // (XXX actually move this check to the global level?
            // requires Git though. OR move the option to BuildOpts.)
            // Verify that this is not an outdated version of the program.
            let found = git_log_version_checker.check_git_log(
                base_path,
                &[HTML_FILE.path_from_repo_top, MD_FILE.path_from_repo_top],
                Some(format!(
                    "you should update your copy of the {PROGRAM_NAME} program. \
                     If you're sure you want to proceed anyway, use the \
                     --no-version-check option."
                )),
            )?;
            if found.is_none() {
                println!(
                    "Warning: could not find or parse {PROGRAM_NAME} version statements \
                     in the git log on the output files; this may mean that \
                     this is a fresh xmlhub Git repository, or something is messed up. \
                     This means that if {PROGRAM_NAME} is used from another computer, \
                     if its version is producing different output from this version \
                     then each will overwrite the changes from the other endlessly."
                );
            }
        }

        // Get the paths from running `git ls-files` inside the
        // directory at base_path, then ignore all files that don't
        // end in .xml
        let mut paths = if build_opts.ignore_untracked {
            // Ask Git for the list of files
            git_ls_files(base_path)?
        } else {
            // Ask the filesystem for the list of files, but do not
            // waste time listing paths in the .git nor .xmlhub
            // subdirs
            let ignored_file_names = HashSet::from([".git", &*DAEMON_FOLDER_NAME]);
            let entries = WalkDir::new(base_path)
                .follow_links(false)
                .min_depth(1)
                .into_iter()
                .filter_entry(|entry| {
                    if let Some(file_name) = entry.file_name().to_str() {
                        !ignored_file_names.contains(file_name)
                    } else {
                        // invalid encoding; XX: what to do? Try to keep those:
                        true
                    }
                });
            let shared_base_path = Arc::new(base_path.to_owned());
            let mut paths: Vec<BaseAndRelPath> = Vec::new();
            for entry in entries {
                let entry = entry
                    .with_context(|| anyhow!("listing contents of directory {base_path:?}"))?;
                let relative_path = entry.path().strip_prefix(base_path).with_context(|| {
                    // Could happen via folder rename races, right? So don't panic.
                    anyhow!(
                        "listed files of directory {base_path:?} \
                         should be prefixed with that path, but got {:?}",
                        entry.path()
                    )
                })?;
                paths.push(BaseAndRelPath::new(
                    Some(shared_base_path.clone()),
                    relative_path.to_owned(),
                ));
            }
            paths
        };
        paths.retain(|path| {
            if let Some(ext) = path.extension() {
                ext.eq_ignore_ascii_case("xml")
            } else {
                false
            }
        });
        // Sort entries ourselves out of a worry that git ls-files
        // might not guarantee a sort order. (The sort order
        // determines the ID assignment that happens later, and those
        // are used in the HTML output, hence would lead to useless
        // commits.)
        paths.sort_by(|a, b| a.rel_path().cmp(b.rel_path()));
        // Move `paths` to the variable with the same name in the
        // outer scope.
        paths
    };

    // Map each file to the info extracted from it (or `FileErrors`
    // when there were errors), including path and an id, held in a
    // `FileInfo` struct. Generate the ids on the go for each of them
    // by `enumerate`ing the values (the enumeration number value is
    // passed as the `id` argument to the function given to `map`).
    // The id is used to refer to each item in document-local links in
    // the generated HTML/Markdown files.
    let fileinfo_or_errors: Vec<Result<FileInfo, FileErrors>> = {
        paths
            .into_par_iter()
            .enumerate()
            .map(|(id, path)| -> Result<FileInfo, FileErrors> {
                let xmldocument = read_xml_file(&path.full_path()).map_err(|e| FileErrors {
                    path: path.clone(),
                    errors: vec![format!("{e:#}")],
                })?;
                let metadata =
                    parse_comments(xmldocument.header_comments()).map_err(|errors| FileErrors {
                        path: path.clone(),
                        errors,
                    })?;
                // We're currently doing nothing else with
                // `xmldocument` (which holds the tree of all elements
                // in the document). It would be possible to extract
                // information from the XML tree for further indexes
                // by defining another kind of indexing than metadata
                // attributes, defining extractors for those, doing
                // the extraction here and adding the results to
                // `FileInfo`.
                Ok(FileInfo { id, path, metadata })
            })
            .collect()
    };

    // Partition fileinfo_or_errors into vectors with only the
    // successful and only the erroneous results.
    let (file_infos, file_errorss): (Vec<FileInfo>, Vec<FileErrors>) =
        fileinfo_or_errors.into_iter().partition_result();

    // Build the HTML fragments to use in the HTML page and the Markdown
    // file.

    // Create all the sections making up the output file(s)

    // Calculate the sections in parallel (first make a tuple with
    // argument-less anonymous functions, then call `par_run` on it
    // which evaluates each function potentially in parallel and
    // returns a tuple with the results, which we then call
    // `transpose` on to move error values up so they (well, the first
    // one found) can easily be propagated via `?`)
    let (file_info_boxes_section, index_sections_section, errors_section) = (
        // Create a Section with boxes with the metainfo for all XML
        // files, in a hierarchy reflecting the folder hierarchy where
        // they are.
        || -> Result<Section> {
            // Temporarily create a folder hierarchy from all the paths,
            // then convert it to a Section.

            let mut folder = Folder::new();
            for file_info in &file_infos {
                folder.add(file_info).expect("no duplicates");
            }
            // This being the last expression in a { } block returns
            // (moves) its value to the `file_info_boxes_section`
            // variable outside.
            folder.to_section(Some("File info by folder".into()))
        },
        // Create all indices for those metadata entries for which their
        // specification says to index them. Each index is in a separate
        // `Section`, but all are bundled as subsections in a single `Section`.
        || -> Result<Section> {
            let index_sections: Vec<Section> = METADATA_SPECIFICATION
                .into_par_iter()
                .filter_map(|spec| {
                    // Get a `KeyStringPreparation` instance if
                    // indexing is desired, if we got one we build an
                    // index; if we got none, `map` also returns
                    // `None`, which is dropped by `filter_map`.
                    spec.indexing
                        .key_string_preparation()
                        .map(|prep| build_index_section(spec.key, prep, &file_infos))
                })
                .collect::<Result<Vec<_>>>()?;
            Ok(Section {
                in_red: false,
                title: Some("Index by attribute".into()),
                intro: None,
                subsections: index_sections,
            })
        },
        // Make an optional `Section` with all the errors if there are any
        || -> Result<Option<Section>> {
            if file_errorss.is_empty() {
                Ok(None)
            } else {
                let html = HTML_ALLOCATOR_POOL.get();

                let mut vec = html.new_vec();
                for file_errors in &file_errorss {
                    vec.push_flat(file_errors.to_html(&html)?)?;
                }
                Ok(Some(Section {
                    in_red: true,
                    title: Some("Errors".into()),
                    intro: Some(html.preserialize(html.dl([], vec)?)?),
                    subsections: vec![],
                }))
            }
        },
    )
        .par_run()
        .transpose()?;

    // Create a single section without a title, to enclose all the
    // other sections. This way, creating the table of contents and
    // conversion to HTML vs. Markdown works seamlessly.
    let toplevel_section = Section {
        in_red: false,
        title: None,
        intro: None,
        subsections: append(
            // This converts the optional `errors_section` from an
            // Option<Section> to a Vec<Section> that contains 0 or 1
            // sections.
            errors_section.into_iter().collect::<Vec<_>>(),
            // Always use the file_info_boxes_section and the index
            // sections.
            vec![index_sections_section, file_info_boxes_section],
        ),
    };

    let html = HTML_ALLOCATOR_POOL.get();

    // Some variables used in both the .html and .md documents
    let now = Local::now().to_rfc2822();
    let title = "XML Hub file index";
    let toc_html: SerHtmlFrag =
        html.preserialize(toplevel_section.to_toc_html(NumberPath::empty(), &html)?)?;
    let generated_message = format!(
        "auto-generated by {PROGRAM_NAME}, {}",
        SOURCE_CHECKOUT.supposed_upstream_web_url
    );

    // (For an explanation of the HTML creation syntax used below, see
    // the comment "The first list passed" further above.)

    // The contents for the README.html document
    let make_htmldocument = |html: &HtmlAllocator| -> Result<AId<Node>> {
        html.html(
            [],
            [
                html.head(
                    [],
                    [
                        html.meta(
                            [att("name", "generator"), att("content", &generated_message)],
                            [],
                        )?,
                        html.meta(
                            [att("name", "author"), att("content", &generated_message)],
                            [],
                        )?,
                        html.title([], html.text("Index - XML Hub")?)?,
                        html.style([], html.text(css_styles())?)?,
                    ],
                )?,
                html.body(
                    [],
                    [
                        html.h1([], html.text(title)?)?,
                        make_intro(false, html)?,
                        html.h2([], html.text("Contents")?)?,
                        html.preserialized(toc_html.clone())?,
                        html.div([], toplevel_section.to_html(NumberPath::empty(), html)?)?,
                        if build_opts.timestamp {
                            html.div(
                                [],
                                [
                                    html.hr([], [])?,
                                    html.p([], [html.text("Last updated: ")?, html.text(&now)?])?,
                                ],
                            )?
                        } else {
                            html.empty_node()?
                        },
                        empty_space_element(40, html)?,
                    ],
                )?,
            ],
        )
    };

    fn flatten_as_paragraphs(vecs: Vec<Vec<StringTree>>) -> Vec<StringTree> {
        intersperse_with(vecs.into_iter().flatten(), || "\n\n".into()).collect()
    }

    // The contents for the README.md document
    let make_mddocument = || -> Result<StringTree> {
        let html = HTML_ALLOCATOR_POOL.get();

        Ok(StringTree::Branching(flatten_as_paragraphs(vec![
            vec![
                format!("<!-- NOTE: {generated_message}, do not edit manually! -->").into(),
                format!("# {title}").into(),
                make_intro(true, &html)?
                    .to_html_fragment_string(&html)?
                    .into(),
                "## Contents".into(),
                toc_html.as_arc_str().into(),
                toplevel_section.to_markdown(NumberPath::empty())?,
                empty_space_element(40, &html)?
                    .to_html_fragment_string(&html)?
                    .into(),
            ],
            if build_opts.timestamp {
                vec![
                    "-------------------------------------------------------".into(),
                    format!("Last updated: {now}\n").into(),
                ]
            } else {
                vec![]
            },
        ])))
    };

    // The contents for the ATTRIBUTES_FILE
    let make_attributes_md = || -> Result<StringTree> {
        let html = HTML_ALLOCATOR_POOL.get();

        let spec_html = specifications_to_html(&html)?.to_html_fragment_string(&html)?;

        let link_to_contribute_file = html
            .a(
                [att("href", format!("{}.md", CONTRIBUTE_FILENAME))],
                html.text(format!("{}", CONTRIBUTE_FILENAME))?,
            )?
            .to_html_fragment_string(&html)?;

        Ok(StringTree::Branching(flatten_as_paragraphs(vec![vec![
            format!("<!-- NOTE: {generated_message}, do not edit manually! -->").into(),
            format!("# Metainfo attributes").into(),
            format!(
                "This describes how each attribute from the XML file headers \
                 (as described by {link_to_contribute_file}) is interpreted. \
                 These are defined by the the constant `METADATA_SPECIFICATION` \
                 in {:?} and can easily be changed there. `required` means that \
                 an actual non-empty value is required, just the presence of \
                 the attribute is not enough.",
                file!()
            )
            .into(),
            spec_html.into(),
        ]])))
    };

    let have_errors = !file_errorss.is_empty();

    // The behaviour of the program in the face of errors depends on 3
    // command line options. Here's the logic that derives 3
    // behaviours from the 3 options (it's not 1:1). The Rust compiler
    // verifies that each of the 3 variables is set exactly once.
    let exit_code;
    let write_errors_to_stderr;
    let write_files;
    if !have_errors {
        exit_code = 0;
        write_errors_to_stderr = false;
        write_files = true;
    } else {
        if build_opts.write_errors {
            write_files = true;
            if build_opts.silent_on_written_errors {
                exit_code = 0;
                write_errors_to_stderr = false;
            } else {
                write_errors_to_stderr = true;
                if build_opts.ok_on_written_errors {
                    exit_code = 0;
                } else {
                    exit_code = 1;
                }
            }
        } else {
            exit_code = 1;
            write_errors_to_stderr = true;
            write_files = false;
        }
    }

    if write_errors_to_stderr {
        let mut out = stderr().lock();
        (|| -> Result<()> {
            writeln!(&mut out, "Indexing errors:")?;
            for file_errors in file_errorss {
                file_errors.print_plain(&mut out)?
            }
            Ok(())
        })()
        .context("writing to stderr")?;
    }

    let html_file_has_changed;
    if write_files {
        (html_file_has_changed, (), ()) = (
            || -> Result<_> {
                let html = HTML_ALLOCATOR_POOL.get();

                // Get an owned version of the base path and then
                // append path segments to it.
                let mut path = xmlhub_checkout.working_dir_path.to_owned();
                path.push(HTML_FILE.path_from_repo_top);
                let mut out = BufWriter::new(File::create(&path)?);
                html.print_html_document(make_htmldocument(&html)?, &mut out)?;
                out.flush()?;

                let mut html_file_has_changed = false;
                if build_opts.open_if_changed {
                    // Need to remember whether the file has changed
                    check_dry_run! {
                        message: "git diff",
                        html_file_has_changed = !git(
                            xmlhub_checkout.working_dir_path,
                            &["diff", "--no-patch", "--exit-code", "--",
                              HTML_FILE.path_from_repo_top],
                            false
                        )?
                    }
                }
                Ok(html_file_has_changed)
            },
            || -> Result<_> {
                let mut path = xmlhub_checkout.working_dir_path.to_owned();
                path.push(MD_FILE.path_from_repo_top);
                make_mddocument()?
                    .write_to_file(&path)
                    .with_context(|| anyhow!("writing to file {path:?}"))?;
                Ok(())
            },
            || -> Result<_> {
                let mut path = xmlhub_checkout.working_dir_path.to_owned();
                path.push(ATTRIBUTES_FILE.path_from_repo_top);
                make_attributes_md()?
                    .write_to_file(&path)
                    .with_context(|| anyhow!("writing to file {path:?}"))?;
                Ok(())
            },
        )
            .par_run()
            .transpose()?;

        let written_files = OUTPUT_FILES.map(|o| o.path_from_repo_top);

        // Commit files if not prevented by --no-commit, and any
        // were written, and --no-commit-errors was not given or
        // there were no errors. I.e. reasons not to commit:
        let no_commit_files = build_opts.no_commit
            || written_files.is_empty()
            || (have_errors && build_opts.no_commit_errors);
        let do_commit_files = !no_commit_files;
        if do_commit_files {
            if !build_opts.no_branch_check {
                // Are we on the expected branch? NOTE: unlike most
                // checks on the repository, this one occurs late, but
                // we can't move it earlier if we want it to be
                // conditional on the need to actually commit.
                xmlhub_checkout.check_current_branch()?;
            }

            // Check that there are no uncommitted changes
            let mut items: Vec<GitStatusItem> = vec![];
            check_dry_run! {
                message: "git status",
                items = git_status(xmlhub_checkout.working_dir_path)?
            }
            let daemon_folder_name_with_slash = format!("{}/", *DAEMON_FOLDER_NAME);
            let ignore_path = |path: &str| -> bool {
                written_files.contains(&path) || path == daemon_folder_name_with_slash
            };
            let changed_items: Vec<String> = items
                .iter()
                .filter(|item| !ignore_path(item.path.as_str()))
                .map(|item| item.to_string())
                .collect();
            if !changed_items.is_empty() {
                // Avoid making this message look like a failure?
                // Hence do not use `bail!`, but just `eprintln!` with
                // a multi-line message, and return an error exit code
                // explicitly.
                eprintln!(
                    "\nFinished build, but won't run git commit due to uncommitted changes in {:?}:\n\
                     {}{}\n\
                     (Note: use the --no-commit option to suppress this error.)",
                    xmlhub_checkout.working_dir_path,
                    "  ",
                    changed_items.join("\n  "),
                );
                return Ok(1);
            }

            check_dry_run! {
                message: format!("git add -f -- {written_files:?}"),
                git(
                    xmlhub_checkout.working_dir_path,
                    &append(&["add", "-f", "--"], &written_files),
                    global_opts.quiet
                )?
            }

            let mut did_commit = true;
            check_dry_run! {
                message: format!("git commit -m .. -- {written_files:?}"),
                did_commit = git(
                    xmlhub_checkout.working_dir_path,
                    &append(
                        &[
                            "commit",
                            "-m",
                            &format!(
                                "regenerate index file{} via {}",
                                if written_files.len() > 1 { "s" } else { "" },
                                git_log_version_checker.program_name_and_version()
                            ),
                            "--",
                        ],
                        &written_files,
                    ),
                    global_opts.quiet
                )?
            }

            if let Some(checked_xmlhub_checkout) = maybe_checked_xmlhub_checkout {
                let default_remote_for_push = &checked_xmlhub_checkout.default_remote;
                if did_commit {
                    check_dry_run! {
                        message: format!("git push {default_remote_for_push:?}"),
                        git_push::<&str>(
                            xmlhub_checkout.working_dir_path,
                            default_remote_for_push,
                            &[],
                            global_opts.quiet
                        )?
                    }
                } else {
                    if !global_opts.quiet {
                        println!("There were no changes to commit, thus not pushing.")
                    }
                }
            }
        }
    } else {
        html_file_has_changed = false;
    }

    // Open a web browser if appropriate
    if build_opts.open || (build_opts.open_if_changed && html_file_has_changed) {
        if write_files {
            // Hopefully all browsers take relative paths? Firefox
            // on Linux and macOS are OK, Safari (via open -a) as
            // well.  Otherwise would have to resolve base_path
            // with HTML_FILENAME pushed-on as an absolute path:
            // let mut path = base_path.clone();
            // path.push(HTML_FILENAME);
            // path.canonicalize().as_os_str()
            spawn_browser(base_path, &[HTML_FILE.path_from_repo_top.as_ref()])?;
        } else {
            eprintln!(
                "Note: not opening browser because the files weren't written due \
                 to errors; specify --write-errors if you want to write and open \
                 the file with the errors"
            );
        }
    }

    Ok(exit_code)
}

/// Execute a `build` command: prepare and run `build_index` in the
/// requested mode (interactive, batch, daemon).
fn build_command(
    program_version: GitVersion<SemVersion>,
    global_opts: &Opts,
    build_opts: &BuildOpts,
) -> Result<()> {
    let base_path = build_opts
        .base_path
        .as_ref()
        .ok_or_else(|| anyhow!("missing BASE_PATH argument. Run --help for help."))?;

    let git_log_version_checker = GitLogVersionChecker {
        program_name: PROGRAM_NAME.into(),
        program_version,
    };

    let xmlhub_checkout = XMLHUB_CHECKOUT
        .replace_working_dir_path(base_path)
        .check1()?;

    // For pushing, need the `CheckedCheckoutContext` (which has the
    // `default_remote`). Retrieve this early to avoid committing and
    // then erroring out on pushing
    let maybe_checked_xmlhub_checkout = if build_opts.push {
        Some(xmlhub_checkout.clone().check2()?)
    } else {
        None
    };

    let min_sleep_seconds = build_opts
        .daemon_sleep_time
        .unwrap_or(MIN_SLEEP_SECONDS_DEFAULT);

    let build_index_once = || {
        build_index(
            &global_opts,
            &build_opts,
            base_path,
            &git_log_version_checker,
            &xmlhub_checkout,
            &maybe_checked_xmlhub_checkout,
        )
    };

    let daemon_base_dir = base_path.append(&*DAEMON_FOLDER_NAME);
    let _ = create_dir(&daemon_base_dir);

    let main_lock_path = (&daemon_base_dir).append("main.lock");
    let get_main_lock = || {
        file_lock_nonblocking(&main_lock_path, true).map_err(|e| match e {
            FileLockError::AlreadyLocked => {
                anyhow!("xmlhub is already running on this repository, {base_path:?}")
            }
            _ => anyhow!("locking {main_lock_path:?}: {e}"),
        })
    };

    if let Some(daemon_mode) = build_opts.daemon {
        let daemon = Daemon {
            base_dir: daemon_base_dir,
            use_local_time: global_opts.localtime,
            max_log_file_size: global_opts
                .max_log_file_size
                .unwrap_or(MAX_LOG_FILE_SIZE_DEFAULT),
            max_log_files: global_opts.max_log_files.unwrap_or(MAX_LOG_FILES_DEFAULT),
            run: move || {
                let _main_lock = get_main_lock()?;

                // Daemon: repeatedly carry out the work by starting a new
                // child process to do it (so that the child crashing or being
                // killed due to out of memory conditions does not stop the
                // daemon).
                forking_loop(
                    LoopWithBackoff {
                        min_sleep_seconds,
                        max_sleep_seconds: MAX_SLEEP_SECONDS,
                        verbose: !global_opts.quiet,
                        ..Default::default()
                    },
                    // The action run in the child process: build the
                    // index once, throwing away the Ok return value
                    // (replacing it with `()`, since `forking_loop`
                    // expects that (it exits the child with exit code
                    // 0 whenever the action returned Ok, and that's
                    // OK for us, thus we can and need to drop the
                    // code from `build_index`).
                    || build_index_once().map(|_exit_code| ()),
                )
            },
        };
        daemon.execute(daemon_mode)?;
        std::process::exit(0);
    } else {
        let _main_lock = get_main_lock()?;
        std::process::exit(build_index_once()?);
    }
}

/// Execute a `clone-to` command.
fn clone_to_command(
    _program_version: GitVersion<SemVersion>,
    global_opts: &Opts,
    command_opts: &CloneOpts,
) -> Result<()> {
    let CloneOpts {
        no_verbose,
        base_path,
    } = command_opts;

    let base_path = base_path
        .as_ref()
        .ok_or_else(|| anyhow!("missing BASE_PATH argument. Run --help for help."))?;

    // Define a macro to only run $body if opts.dry_run is false,
    // otherwise show $message instead, or show $message anyway if
    // command_opts.no_verbose is false.
    macro_rules! check_dry_run {
        { message: $message:expr, $body:expr } => {
            let s = || -> String { $message.into() };
            if global_opts.dry_run {
                eprintln_dry_run(s());
            } else {
                if ! no_verbose {
                    eprintln_running(s());
                }
                $body;
            }
        }
    }

    let checkout = XMLHUB_CHECKOUT.replace_working_dir_path(base_path);

    if base_path.is_dir() && base_path.append(".git").is_dir() {
        eprintln!("git checkout at {base_path:?} already exists, just configuring it");
    } else {
        let parent_dir = base_path
            .parent()
            .ok_or_else(
                // This only happens for the path "".
                || anyhow!("the given path {base_path:?} has no parent directory"),
            )?
            .fixup();

        let url = checkout.supposed_upstream_git_url;

        let subfolder_name = base_path.file_name().ok_or_else(|| {
            anyhow!("the given path {base_path:?} is missing the subdirectory name")
        })?;

        check_dry_run! {
            message: format!("cd {:?} && git clone {:?} {:?}",
                             parent_dir,
                             url,
                             subfolder_name),
            git(
                &parent_dir,
                &[ OsString::from("clone"), OsString::from(url), subfolder_name.into() ],
                false
            )?
        }

        if !global_opts.dry_run {
            checkout.check1()?;
        }
    }

    check_dry_run! {
        message: format!("cd {:?} && git config pull.rebase false", base_path),
        git(
            base_path,
            &[ "config", "pull.rebase", "false" ],
            false
        )?
    }

    Ok(())
}

/// Returns the converted file contents, and whether that content is
/// different from the original. Errors already mention the
/// `source_path`.
fn prepare_file(
    source_path: &Path,
    no_blind: bool,
    blind_comment: &Option<String>,
) -> Result<(String, bool)> {
    let xmldocument = read_xml_file(source_path)
        .with_context(|| anyhow!("loading the XML file {source_path:?}"))?;

    let beast_version = get_beast_version(xmldocument.document())
        .with_context(|| anyhow!("preparing the file from {source_path:?}"))?;

    // XX TODO: check if the document already has an xmlhub header?

    let mut modified_document = ModifiedXMLDocument::new(&xmldocument);

    // Add header template
    for att in METADATA_SPECIFICATION {
        let comment = format!(
            "{}: {}",
            att.key.as_ref(),
            if att.need == AttributeNeed::Optional {
                "NA"
            } else {
                ""
            }
        );
        modified_document.insert_comment_at_the_top(&comment, "  ");
    }

    // Optionally, delete (blind) data
    if !no_blind {
        if beast_version.major != BeastMajorVersion::Two {
            bail!(
                "currently, can only blind BEAST 2 files, but this file specifies version {:?}: \
                 {source_path:?} (for BEAST 1 or 3.. files, blind manually or via the \
                 `beast1blinder.py` script and specify the `--no-blind` \
                 option)",
                beast_version.string
            )
        }

        let comment = blind_comment
            .as_ref()
            .map(|s| s.as_str())
            .unwrap_or(DEFAULT_COMMENT_FOR_BLINDED_DATA);
        modified_document.clear_elements_named("data", Some((comment, "    ")), false);
    }

    Ok(modified_document.to_string_and_modified()?)
}

fn overwrite_file_moving_to_trash_if_exists(
    target_path: &Path,
    content: &str,
    quiet: bool,
) -> Result<()> {
    if target_path.exists() {
        trash::delete(&target_path)
            .with_context(|| anyhow!("moving existing target file {target_path:?} to trash"))?;
        if !quiet {
            println!("moved existing target {target_path:?} to trash");
        }
    }
    std::fs::write(&target_path, content)
        .with_context(|| anyhow!("writing contents to file {target_path:?}"))?;
    Ok(())
}

/// Execute a `prepare` command.
fn prepare_command(
    _program_version: GitVersion<SemVersion>,
    global_opts: &Opts,
    command_opts: &PrepareOpts,
) -> Result<()> {
    let PrepareOpts {
        files_to_prepare,
        no_blind,
        blind_comment,
    } = command_opts;

    // First, convert them all without writing them out, to avoid
    // writing only some of them (which would then exist when
    // re-running the same command, also it will be a bit
    // confusing). With regards to IO, only reading happens here.
    let converted: Vec<(&PathBuf, (String, bool))> = files_to_prepare
        .into_iter()
        .map(|source_path| {
            Ok((
                source_path,
                prepare_file(source_path, *no_blind, blind_comment)?,
            ))
        })
        .collect::<Result<_>>()?;

    // Now that all files were read and converted successfully, write
    // them out. With regards to IO, only writing happens here.
    for (target_path, (output_string, modified)) in converted {
        if modified {
            overwrite_file_moving_to_trash_if_exists(
                &target_path,
                &output_string,
                global_opts.quiet,
            )?;
        } else {
            if !global_opts.quiet {
                println!("note: the file {target_path:?} is unchanged (already prepared)");
            }
        }
    }
    Ok(())
}

/// Execute an `add` command.
fn add_command(
    _program_version: GitVersion<SemVersion>,
    global_opts: &Opts,
    command_opts: &AddOpts,
) -> Result<()> {
    let AddOpts {
        target_directory,
        files_to_add,
        mkdir,
        no_blind,
        blind_comment,
        force,
    } = command_opts;

    let target_directory = target_directory
        .as_ref()
        .ok_or_else(|| anyhow!("missing TARGET_DIRECTORY argument. Run --help for help."))?;

    if !target_directory.is_dir() {
        if *mkdir {
            create_dir(target_directory)
                .with_context(|| anyhow!("creating target directory {target_directory:?}"))?
        } else {
            bail!(
                "given TARGET_DIRECTORY path {target_directory:?} does not exist. \
                   Add the --mkdir option if you want to create it."
            )
        }
    }

    let file_or_files = english_plural(files_to_add.len(), "files");

    if !global_opts.quiet {
        println!("Reading the {file_or_files}...");
    }

    // First, convert them all without writing them out, to avoid
    // writing only some of them (which would then exist when
    // re-running the same command, also it will be a bit
    // confusing). With regards to IO, only reading happens here.
    let converted: Vec<_> = files_to_add
        .into_iter()
        .map(|source_path| {
            Ok((
                source_path,
                prepare_file(source_path, *no_blind, blind_comment)?,
            ))
        })
        .collect::<Result<_>>()?;

    // Convert the paths to the output paths; no IO happens here.
    let outputs: Vec<(PathBuf, (String, bool))> = converted
        .into_iter()
        .map(|(source_path, converted_contents)| -> Result<_> {
            let file_name = source_path
                .file_name()
                .with_context(|| anyhow!("given path {source_path:?} is missing file name"))?;
            let target_path = target_directory.append(file_name);
            Ok((target_path, converted_contents))
        })
        .collect::<Result<_>>()?;

    // Stop if any of the files exist, by default.
    if !force {
        let existing_target_paths: Vec<&PathBuf> = outputs
            .iter()
            .filter_map(|(path, _)| if path.exists() { Some(path) } else { None })
            .collect();
        if !existing_target_paths.is_empty() {
            bail!(
                "these target paths already exist--specify the --force option to overwrite: \
                 {existing_target_paths:#?}"
            )
        }
    }

    if !global_opts.quiet {
        println!("Writing the {file_or_files}...");
    }

    // Now that all files were read, converted and target-checked
    // successfully, write them out. With regards to IO, only writing
    // happens here.
    for (target_path, (output_string, _modified)) in outputs {
        // Note: ignore _modified as that is with regards to the
        // source path, which is a different path. We need to copy the
        // file even if no modification is carried out at the same
        // time!

        // Keep existing files in trash, even with --force?
        overwrite_file_moving_to_trash_if_exists(&target_path, &output_string, global_opts.quiet)?;
    }

    if !global_opts.quiet {
        println!(
            "Done. Now edit the new {file_or_files} in {target_directory:?} \
             to complete the metadata."
        );
    }

    Ok(())
}

fn main() -> Result<()> {
    let program_version: GitVersion<SemVersion> = PROGRAM_VERSION
        .parse()
        .with_context(|| anyhow!("the git tag for the release version is not in a valid format"))?;

    // Retrieve the command line options / arguments, and fix
    // those that are overridden by others.
    let global_opts = {
        // Create an `Opts` from program arguments then deconstruct it
        // immediately, binding the values in the fields to same-named
        // variables, except where followed by `:`, in which case
        // binding the value to a variable with an underscore appended
        // to the field name.
        let Opts {
            v,
            verbose,
            dry_run,
            no_version_check,
            quiet,
            localtime,
            max_log_file_size,
            max_log_files,
            help_contributing,
            command,
        } = Opts::parse();

        if help_contributing {
            // XX sigh, spawn_browser is badly prepared for external urls,
            // (1) should not need a directory, (2) should not require
            // arguments to be OsStr.
            spawn_browser(&PathBuf::from("/"), &[&OsString::from(
            "https://cevo-git.ethz.ch/cevo-resources/xmlhub/-/blob/master/CONTRIBUTE.md?ref_type=heads"
        )])?;
            return Ok(());
        }

        if v {
            println!("{REPO_NAME} {program_version}");
            return Ok(());
        }

        match command {
            Some(command) => match command {
                Command::Build(BuildOpts {
                    timestamp: timestamp_,
                    write_errors: write_errors_,
                    no_commit_errors: no_commit_errors_,
                    ok_on_written_errors,
                    silent_on_written_errors: silent_on_written_errors_,
                    open,
                    open_if_changed,
                    pull: pull_,
                    no_commit: no_commit_,
                    push: push_,
                    batch: batch_,
                    no_branch_check,
                    daemon,
                    daemon_sleep_time,
                    base_path,
                    ignore_untracked,
                }) => {
                    // Create uninitialized variables without the underscores,
                    // then initialize them differently depending on some of the
                    // options (--batch, --daemon).
                    let (
                        pull,
                        push,
                        no_commit,
                        write_errors,
                        no_commit_errors,
                        silent_on_written_errors,
                        timestamp,
                        batch,
                    );
                    if daemon.is_some() {
                        batch = true;
                    } else {
                        batch = batch_;
                    }
                    if batch {
                        pull = false;
                        push = true;
                        no_commit = false;
                        write_errors = true;
                        no_commit_errors = false;
                        silent_on_written_errors = true;
                        timestamp = false;
                        // Should we force `ignore_untracked` false?
                    } else {
                        pull = pull_;
                        push = push_;
                        no_commit = no_commit_;
                        write_errors = write_errors_;
                        no_commit_errors = no_commit_errors_;
                        silent_on_written_errors = silent_on_written_errors_;
                        timestamp = timestamp_;
                    }

                    // Pack the variables into a new struct
                    Opts {
                        v,
                        help_contributing,
                        verbose,
                        quiet,
                        localtime,
                        max_log_file_size,
                        max_log_files,
                        dry_run,
                        no_version_check,
                        command: Some(Command::Build(BuildOpts {
                            timestamp,
                            write_errors,
                            no_commit_errors,
                            ok_on_written_errors,
                            silent_on_written_errors,
                            open,
                            open_if_changed,
                            pull,
                            no_commit,
                            push,
                            batch,
                            daemon,
                            daemon_sleep_time,
                            no_branch_check,
                            ignore_untracked,
                            base_path,
                        })),
                    }
                }
                Command::CloneTo(CloneOpts {
                    no_verbose,
                    base_path,
                }) => Opts {
                    v,
                    help_contributing,
                    verbose,
                    quiet,
                    localtime,
                    max_log_file_size,
                    max_log_files,
                    dry_run,
                    no_version_check,
                    command: Some(Command::CloneTo(CloneOpts {
                        no_verbose,
                        base_path,
                    })),
                },
                Command::Prepare(PrepareOpts {
                    files_to_prepare,
                    no_blind,
                    blind_comment,
                }) => Opts {
                    v,
                    help_contributing,
                    verbose,
                    quiet,
                    localtime,
                    max_log_file_size,
                    max_log_files,
                    dry_run,
                    no_version_check,
                    command: Some(Command::Prepare(PrepareOpts {
                        files_to_prepare,
                        no_blind,
                        blind_comment,
                    })),
                },
                Command::Add(AddOpts {
                    target_directory,
                    files_to_add,
                    mkdir,
                    no_blind,
                    blind_comment,
                    force,
                }) => Opts {
                    v,
                    help_contributing,
                    verbose,
                    quiet,
                    localtime,
                    max_log_file_size,
                    max_log_files,
                    dry_run,
                    no_version_check,
                    command: Some(Command::Add(AddOpts {
                        target_directory,
                        files_to_add,
                        mkdir,
                        no_blind,
                        blind_comment,
                        force,
                    })),
                },
            },
            None => {
                bail!("missing command argument. Please run with the `--help` option for help.")
            }
        }
    };

    // Run the requested command
    match global_opts
        .command
        .as_ref()
        .expect("`None` is dispatched above already")
    {
        Command::Build(command_opts) => build_command(program_version, &global_opts, command_opts),
        Command::CloneTo(command_opts) => {
            clone_to_command(program_version, &global_opts, command_opts)
        }
        Command::Prepare(command_opts) => {
            prepare_command(program_version, &global_opts, command_opts)
        }
        Command::Add(command_opts) => add_command(program_version, &global_opts, command_opts),
    }
}
